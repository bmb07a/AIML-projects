{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project - Twitter US Airline Sentiment - Brandon Bowen.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BFaqeH75un_H"
      },
      "source": [
        "# Project - Twitter US Airline Sentiment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dei3HrO7uHmu"
      },
      "source": [
        "**Background and Context:**\n",
        "\n",
        "Twitter posses 330 million monthly active users, which allows businesses to reach a broad population and connect with customers without intermediaries. On the other side, there’s so much information that it’s difficult for brands to quickly detect negative social mentions that could harm their business.\n",
        "\n",
        "That's why sentiment analysis/classification, which involves monitoring emotions in conversations on social media platforms, has become a key strategy in social media marketing.\n",
        "\n",
        "\n",
        "Listening to how customers feel about the product/services on Twitter allows companies to understand their audience, keep on top of what’s being said about their brand and their competitors, and discover new trends in the industry.\n",
        "\n",
        " \n",
        "\n",
        "**Data Description:**\n",
        "\n",
        "A sentiment analysis job about the problems of each major US airline. Twitter data was scraped from February of 2015 and contributors were asked to first classify positive, negative, and neutral tweets, followed by categorizing negative reasons (such as \"late flight\" or \"rude service\").\n",
        "\n",
        " \n",
        "\n",
        "**Dataset:**\n",
        "\n",
        "The dataset has the following columns:\n",
        "\n",
        "- tweet_id                                                           \n",
        "- airline_sentiment                                               \n",
        "- airline_sentiment_confidence                               \n",
        "- negativereason                                                   \n",
        "- negativereason_confidence                                    \n",
        "- airline                                                                   \n",
        "- airline_sentiment_gold                                              \n",
        "- name     \n",
        "- negativereason_gold \n",
        "- retweet_count\n",
        "- text\n",
        "- tweet_coord\n",
        "- tweet_created\n",
        "- tweet_location \n",
        "- user_timezone\n",
        "\n",
        "\n",
        "**Objective:**\n",
        "\n",
        "To implement the techniques learned as a part of the course."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PxHfjbMgvCvp"
      },
      "source": [
        "# 1. Importing Libraries and Loading the Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QZvqZURs7l2k"
      },
      "source": [
        "**Connecting to Google Drive**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FC1eBil6vRO6"
      },
      "source": [
        "from google.colab import drive  # Libary to access the user's Google Drive folders and files"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vrZoYpRdvYde",
        "outputId": "17c3d7c2-4b89-4c33-bd44-bde75919ad10"
      },
      "source": [
        "drive.mount(\"/content/drive\")   # Linking to the user's Google Drive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCC4Gh9Qvduj",
        "outputId": "40b8f3bd-53e0-4dac-cd27-ac8ef0ec80c0"
      },
      "source": [
        "# Libraries for manipulating numbers, datasets and displaying graphs\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "!pip install contractions                         # installing library to remove contractions\n",
        "\n",
        "import contractions                               # library for removing contractions\n",
        "import re                                         # regular expression library\n",
        "import unicodedata                                # library for removing special characters\n",
        "\n",
        "from bs4 import BeautifulSoup                     # library for removing html tags\n",
        "import nltk                                       # library for NLP\n",
        "from nltk.tokenize import word_tokenize           # library for splitting text blocks into words\n",
        "from nltk.corpus import stopwords                 # library for stop words\n",
        "from nltk.corpus import wordnet                   # library for parts of speech\n",
        "from nltk.stem.wordnet import WordNetLemmatizer   # library for lemmatizing words\n",
        "\n",
        "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer  # libraries to transform words into vectors\n",
        "from sklearn.model_selection import train_test_split                          # library to divide data into training and testing\n",
        "from sklearn.metrics import confusion_matrix, classification_report           # library to summarize model performance per class\n",
        "\n",
        "nltk.download(\"punkt\")                            # downloading necessary library dictionaries\n",
        "nltk.download(\"stopwords\")                        # downloading english stop words\n",
        "nltk.download('averaged_perceptron_tagger')       # downloading the parts of speech\n",
        "nltk.download(\"wordnet\")                          # downaloading wordnet\n",
        "\n",
        "from tensorflow.keras.models import Sequential                                                    # Basic wrapper to build model inside\n",
        "from tensorflow.keras.layers import Dense, Dropout                                                # Dense layer is for the ANN , Dropout used to control overfitting\n",
        "from tensorflow.keras.utils import to_categorical                                                 # Function to convert the categorical target classes into tensors for the neural network\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping                             # Used to control overfitting and store the best model during the epochs of training\n",
        "from tensorflow.keras import backend                                                              # Used to clear memory (RAM)\n",
        "\n",
        "# Seeding the random number generator to ensure the model building process is repeatable\n",
        "import random\n",
        "random.seed(0)  # The number zero is not special, basically any integer works\n",
        "\n",
        "# Library to over sample the data in order to balance the target classes\n",
        "from imblearn.over_sampling import SMOTE\n",
        "\n",
        "# Command for the notebook to display graphs (in this case images) in the notebook\n",
        "%matplotlib inline\n",
        "sns.set(color_codes=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: contractions in /usr/local/lib/python3.7/dist-packages (0.0.52)\n",
            "Requirement already satisfied: textsearch>=0.0.21 in /usr/local/lib/python3.7/dist-packages (from contractions) (0.0.21)\n",
            "Requirement already satisfied: anyascii in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (0.2.0)\n",
            "Requirement already satisfied: pyahocorasick in /usr/local/lib/python3.7/dist-packages (from textsearch>=0.0.21->contractions) (1.4.2)\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]     /root/nltk_data...\n",
            "[nltk_data]   Package averaged_perceptron_tagger is already up-to-\n",
            "[nltk_data]       date!\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ORgYgPuovpyU"
      },
      "source": [
        "airData = pd.read_csv(\"/content/drive/My Drive/AIML/8.0/Week 3 Project/Tweets.csv\")   # loading the dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "seF1nlWNwHUp",
        "outputId": "249f5021-511c-455a-8242-109b8d8c89f0"
      },
      "source": [
        "airData.shape   # displaying the shape of the dataset"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 15)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yZ7uzcYk8oPp"
      },
      "source": [
        "There are 14,640 tweets in the dataset with 15 different columns."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "id": "c5QPfQvSwgVg",
        "outputId": "be3cf2dc-7348-4995-f224-bc778e5f3cfb"
      },
      "source": [
        "airData.describe().T    # displaying summary information of the dataset for columns containing numbers"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>mean</th>\n",
              "      <th>std</th>\n",
              "      <th>min</th>\n",
              "      <th>25%</th>\n",
              "      <th>50%</th>\n",
              "      <th>75%</th>\n",
              "      <th>max</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>tweet_id</th>\n",
              "      <td>14640.0</td>\n",
              "      <td>5.692184e+17</td>\n",
              "      <td>7.791112e+14</td>\n",
              "      <td>5.675883e+17</td>\n",
              "      <td>5.685592e+17</td>\n",
              "      <td>5.694779e+17</td>\n",
              "      <td>5.698905e+17</td>\n",
              "      <td>5.703106e+17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline_sentiment_confidence</th>\n",
              "      <td>14640.0</td>\n",
              "      <td>9.001689e-01</td>\n",
              "      <td>1.628300e-01</td>\n",
              "      <td>3.350000e-01</td>\n",
              "      <td>6.923000e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negativereason_confidence</th>\n",
              "      <td>10522.0</td>\n",
              "      <td>6.382983e-01</td>\n",
              "      <td>3.304398e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>3.606000e-01</td>\n",
              "      <td>6.706000e-01</td>\n",
              "      <td>1.000000e+00</td>\n",
              "      <td>1.000000e+00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>retweet_count</th>\n",
              "      <td>14640.0</td>\n",
              "      <td>8.265027e-02</td>\n",
              "      <td>7.457782e-01</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>0.000000e+00</td>\n",
              "      <td>4.400000e+01</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                count          mean  ...           75%           max\n",
              "tweet_id                      14640.0  5.692184e+17  ...  5.698905e+17  5.703106e+17\n",
              "airline_sentiment_confidence  14640.0  9.001689e-01  ...  1.000000e+00  1.000000e+00\n",
              "negativereason_confidence     10522.0  6.382983e-01  ...  1.000000e+00  1.000000e+00\n",
              "retweet_count                 14640.0  8.265027e-02  ...  0.000000e+00  4.400000e+01\n",
              "\n",
              "[4 rows x 8 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2FT1lQd8yOQ"
      },
      "source": [
        "- `tweet_id` does not contain any useful information and will be dropped further on.\n",
        "- Airline sentiment confidence is high with a mean of 0.9 (closer to 1 is better).\n",
        "- Negative reason confidence is mediocre at a mean of 0.63.\n",
        "- At least 75% of tweets had no retweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 390
        },
        "id": "A20hrxmvwioM",
        "outputId": "09922f7b-ca90-4ee1-dfee-322e2f4c3221"
      },
      "source": [
        "airData.describe(include=\"O\").T   # displaying summary information of the dataset for columns containing words"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>count</th>\n",
              "      <th>unique</th>\n",
              "      <th>top</th>\n",
              "      <th>freq</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>airline_sentiment</th>\n",
              "      <td>14640</td>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>9178</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negativereason</th>\n",
              "      <td>9178</td>\n",
              "      <td>10</td>\n",
              "      <td>Customer Service Issue</td>\n",
              "      <td>2910</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline</th>\n",
              "      <td>14640</td>\n",
              "      <td>6</td>\n",
              "      <td>United</td>\n",
              "      <td>3822</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>airline_sentiment_gold</th>\n",
              "      <td>40</td>\n",
              "      <td>3</td>\n",
              "      <td>negative</td>\n",
              "      <td>32</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>name</th>\n",
              "      <td>14640</td>\n",
              "      <td>7701</td>\n",
              "      <td>JetBlueNews</td>\n",
              "      <td>63</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>negativereason_gold</th>\n",
              "      <td>32</td>\n",
              "      <td>13</td>\n",
              "      <td>Customer Service Issue</td>\n",
              "      <td>12</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>text</th>\n",
              "      <td>14640</td>\n",
              "      <td>14427</td>\n",
              "      <td>@united thanks</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweet_coord</th>\n",
              "      <td>1019</td>\n",
              "      <td>832</td>\n",
              "      <td>[0.0, 0.0]</td>\n",
              "      <td>164</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweet_created</th>\n",
              "      <td>14640</td>\n",
              "      <td>14247</td>\n",
              "      <td>2015-02-24 09:54:34 -0800</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>tweet_location</th>\n",
              "      <td>9907</td>\n",
              "      <td>3081</td>\n",
              "      <td>Boston, MA</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>user_timezone</th>\n",
              "      <td>9820</td>\n",
              "      <td>85</td>\n",
              "      <td>Eastern Time (US &amp; Canada)</td>\n",
              "      <td>3744</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                        count unique                         top  freq\n",
              "airline_sentiment       14640      3                    negative  9178\n",
              "negativereason           9178     10      Customer Service Issue  2910\n",
              "airline                 14640      6                      United  3822\n",
              "airline_sentiment_gold     40      3                    negative    32\n",
              "name                    14640   7701                 JetBlueNews    63\n",
              "negativereason_gold        32     13      Customer Service Issue    12\n",
              "text                    14640  14427              @united thanks     6\n",
              "tweet_coord              1019    832                  [0.0, 0.0]   164\n",
              "tweet_created           14640  14247   2015-02-24 09:54:34 -0800     5\n",
              "tweet_location           9907   3081                  Boston, MA   157\n",
              "user_timezone            9820     85  Eastern Time (US & Canada)  3744"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qMijAEj7FUe3"
      },
      "source": [
        "- The majority of the tweets are negative in sentiment.\n",
        "  - This means our target class is unbalanced which we will deal with later on.\n",
        "- Customers listed customer service as the most frequent reason for their negative sentiment.\n",
        "- United airlines has the most tweets of any airline in this dataset.\n",
        "- Tweet meta data does not seem to be helpful based on the number of missing values or values of zero."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hzigohCDwr3K"
      },
      "source": [
        "# 2. Brief View of the Data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F64MwGyexOBQ"
      },
      "source": [
        "a. Dropping all columns except `text` and `airline_sentiment`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IILs-FWixHV9"
      },
      "source": [
        "airData = airData[[\"text\", \"airline_sentiment\"]]    # Grabbing only the two columns we care about"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "k5vLnv-txgNP"
      },
      "source": [
        "b. The new shape of the data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mH4Rqf-Axled",
        "outputId": "c2863108-6c32-455b-aa2b-d146c18b34e4"
      },
      "source": [
        "airData.shape   # printing the shape of the reduced data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F8OgD2aUGU2G"
      },
      "source": [
        "We are now down to only two columns."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XIVtML0xxofY"
      },
      "source": [
        "c. Viewing the first five rows"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "OdA451MRxtKc",
        "outputId": "4dc1b05e-a2d5-484f-d855-1e9c12cac512"
      },
      "source": [
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0                @VirginAmerica What @dhepburn said.           neutral\n",
              "1  @VirginAmerica plus you've added commercials t...          positive\n",
              "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
              "3  @VirginAmerica it's really aggressive to blast...          negative\n",
              "4  @VirginAmerica and it's a really big bad thing...          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aHvHyvscGZvk"
      },
      "source": [
        "d. Checking for missing values"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "08nJ3AOmGcWz",
        "outputId": "1a42509e-79c2-4fb4-e8a5-e4f41be95deb"
      },
      "source": [
        "airData.isnull().sum()    # printing the number of missing or null values"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "text                 0\n",
              "airline_sentiment    0\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L6VSewexGfuz"
      },
      "source": [
        "There are no null or missing values."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MdkjLNpfxu1h"
      },
      "source": [
        "# 3. Text Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D59XwgDCx5PN"
      },
      "source": [
        "### a. HTML Tag Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "FzEVDxGfySZx",
        "outputId": "aeeb0bdd-b593-48af-ece0-d0edc1292b83"
      },
      "source": [
        "# Using the BeautifulSoup function to remove any html tags from the tweet text by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda x: BeautifulSoup(x, \"html.parser\").get_text())\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VirginAmerica plus you've added commercials t...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@VirginAmerica I didn't today... Must mean I n...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@VirginAmerica it's really aggressive to blast...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VirginAmerica and it's a really big bad thing...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0                @VirginAmerica What @dhepburn said.           neutral\n",
              "1  @VirginAmerica plus you've added commercials t...          positive\n",
              "2  @VirginAmerica I didn't today... Must mean I n...           neutral\n",
              "3  @VirginAmerica it's really aggressive to blast...          negative\n",
              "4  @VirginAmerica and it's a really big bad thing...          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZJJLQwCuFTq"
      },
      "source": [
        "### Contraction Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "4JDLLMQCuP4q",
        "outputId": "99542197-55dd-4893-d900-6eca5ba1ebbf"
      },
      "source": [
        "# Using the contraction function to transform any contractions to their full words from the tweet text by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda x: contractions.fix(x))\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>@VirginAmerica What @dhepburn said.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>@VirginAmerica plus you have added commercials...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>@VirginAmerica I did not today... Must mean I ...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>@VirginAmerica it is really aggressive to blas...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>@VirginAmerica and it is a really big bad thin...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0                @VirginAmerica What @dhepburn said.           neutral\n",
              "1  @VirginAmerica plus you have added commercials...          positive\n",
              "2  @VirginAmerica I did not today... Must mean I ...           neutral\n",
              "3  @VirginAmerica it is really aggressive to blas...          negative\n",
              "4  @VirginAmerica and it is a really big bad thin...          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M4wy7zG9zTbo"
      },
      "source": [
        "### b. Tokenization"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "bwvsRjnHz4Gx",
        "outputId": "4f1c7d2b-811c-4ae2-df11-66f9f37255d6"
      },
      "source": [
        "# Using word_tokenize function to split the text in each tweet into a list of words by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "airData[\"text\"]= airData[\"text\"].apply(lambda x: word_tokenize(x))\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, VirginAmerica, What, @, dhepburn, said, .]</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[@, VirginAmerica, plus, you, have, added, com...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, VirginAmerica, I, did, not, today, ..., Mu...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[@, VirginAmerica, it, is, really, aggressive,...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[@, VirginAmerica, and, it, is, a, really, big...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0     [@, VirginAmerica, What, @, dhepburn, said, .]           neutral\n",
              "1  [@, VirginAmerica, plus, you, have, added, com...          positive\n",
              "2  [@, VirginAmerica, I, did, not, today, ..., Mu...           neutral\n",
              "3  [@, VirginAmerica, it, is, really, aggressive,...          negative\n",
              "4  [@, VirginAmerica, and, it, is, a, really, big...          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wmoPM8TZ0cD9"
      },
      "source": [
        "### c. Number Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mrbK3FNz1Fgv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c94e614e-5010-4e5a-aaaa-7e9879d7fc74"
      },
      "source": [
        "# Using regular expressions to remove any numbers (not spelled out) from the tweet text by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda words: [re.sub(pattern=r\"\\d+\", repl=\"\", string=word) for word in words])\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, VirginAmerica, What, @, dhepburn, said, .]</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[@, VirginAmerica, plus, you, have, added, com...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, VirginAmerica, I, did, not, today, ..., Mu...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[@, VirginAmerica, it, is, really, aggressive,...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[@, VirginAmerica, and, it, is, a, really, big...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0     [@, VirginAmerica, What, @, dhepburn, said, .]           neutral\n",
              "1  [@, VirginAmerica, plus, you, have, added, com...          positive\n",
              "2  [@, VirginAmerica, I, did, not, today, ..., Mu...           neutral\n",
              "3  [@, VirginAmerica, it, is, really, aggressive,...          negative\n",
              "4  [@, VirginAmerica, and, it, is, a, really, big...          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AI7UlNXFtvpZ"
      },
      "source": [
        "### d. Removal of Special Characters and Punctuation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "KhHbm7LIt64f",
        "outputId": "150f95d6-25a0-4929-f0b1-1efa956a0195"
      },
      "source": [
        "# Using the unicodedata function to remove any special characters that are not in the normal english language from the tweet text by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda words: [unicodedata.normalize(\"NFKD\", word).encode(\"ascii\", \"ignore\").decode(\"utf-8\", \"ignore\") for word in words])\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[@, VirginAmerica, What, @, dhepburn, said, .]</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[@, VirginAmerica, plus, you, have, added, com...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[@, VirginAmerica, I, did, not, today, ..., Mu...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[@, VirginAmerica, it, is, really, aggressive,...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[@, VirginAmerica, and, it, is, a, really, big...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0     [@, VirginAmerica, What, @, dhepburn, said, .]           neutral\n",
              "1  [@, VirginAmerica, plus, you, have, added, com...          positive\n",
              "2  [@, VirginAmerica, I, did, not, today, ..., Mu...           neutral\n",
              "3  [@, VirginAmerica, it, is, really, aggressive,...          negative\n",
              "4  [@, VirginAmerica, and, it, is, a, really, big...          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "EjWaVFkgvm0Y",
        "outputId": "60914d9f-b662-41fc-aa69-ded7327ab8e3"
      },
      "source": [
        "# Using regular expressions to remove symbols like @ signs, etc. from the tweet text by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda words: [re.sub(pattern=r\"[^\\w\\s]\", repl=\"\", string=word) for word in words])\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda words: [word for word in words if word != \"\"])\n",
        "\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[VirginAmerica, What, dhepburn, said]</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[VirginAmerica, plus, you, have, added, commer...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[VirginAmerica, I, did, not, today, Must, mean...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[VirginAmerica, it, is, really, aggressive, to...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[VirginAmerica, and, it, is, a, really, big, b...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0              [VirginAmerica, What, dhepburn, said]           neutral\n",
              "1  [VirginAmerica, plus, you, have, added, commer...          positive\n",
              "2  [VirginAmerica, I, did, not, today, Must, mean...           neutral\n",
              "3  [VirginAmerica, it, is, really, aggressive, to...          negative\n",
              "4  [VirginAmerica, and, it, is, a, really, big, b...          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ACRviVWZ3APK"
      },
      "source": [
        "### e. Stop Word Removal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UWx_uyid3O22"
      },
      "source": [
        "stopWords = stopwords.words('english')    # loading the english stopwords\n",
        "\n",
        "stopWords = set(stopWords) - set(\"not\")   # removing the word \"not\" from set of stopwords since it can convey meaning for sentiment\n",
        "                                          # there is no need to remove the contraction words the set as there are no longer contractions in our dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "TinTPXT74QiD",
        "outputId": "2f424824-f93d-449e-ab51-5849fa420ad7"
      },
      "source": [
        "# Removing any stop words from the tweet text by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda words: [word for word in words if word not in stopWords])\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[VirginAmerica, What, dhepburn, said]</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[VirginAmerica, plus, added, commercials, expe...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[VirginAmerica, I, today, Must, mean, I, need,...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[VirginAmerica, really, aggressive, blast, obn...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[VirginAmerica, really, big, bad, thing]</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0              [VirginAmerica, What, dhepburn, said]           neutral\n",
              "1  [VirginAmerica, plus, added, commercials, expe...          positive\n",
              "2  [VirginAmerica, I, today, Must, mean, I, need,...           neutral\n",
              "3  [VirginAmerica, really, aggressive, blast, obn...          negative\n",
              "4           [VirginAmerica, really, big, bad, thing]          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "utFwFcAa4i_Y"
      },
      "source": [
        "### f. Conversion to Lowercase"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5ISPCFy14zml",
        "outputId": "3395a8e7-9d3f-44ec-8e0a-0caec2efc17f"
      },
      "source": [
        "# Lowercasing all letters in the tweet text by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda words: [word.lower() for word in words])\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[virginamerica, what, dhepburn, said]</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[virginamerica, plus, added, commercials, expe...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[virginamerica, i, today, must, mean, i, need,...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[virginamerica, really, aggressive, blast, obn...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[virginamerica, really, big, bad, thing]</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0              [virginamerica, what, dhepburn, said]           neutral\n",
              "1  [virginamerica, plus, added, commercials, expe...          positive\n",
              "2  [virginamerica, i, today, must, mean, i, need,...           neutral\n",
              "3  [virginamerica, really, aggressive, blast, obn...          negative\n",
              "4           [virginamerica, really, big, bad, thing]          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B1iPt2Bp5I6d"
      },
      "source": [
        "### g. Lemmatize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A2k6Q6M65WPY"
      },
      "source": [
        "wnl = WordNetLemmatizer()                             # Initializing the lemmatizer\n",
        "\n",
        "# Custom function to evaluate the part of speech of a word (i.e. adjective, noun, verb, adverb)\n",
        "def getPOS(word):\n",
        "    posTag = nltk.pos_tag([word])[0][1][0].upper()    # Uses nltk library to identify word part of speech\n",
        "    tag_dict = {\"J\": wordnet.ADJ,                     # Dictionary to convert the pos_tag into what the lemmatizer can use\n",
        "                \"N\": wordnet.NOUN,\n",
        "                \"VBG\": wordnet.VERB,\n",
        "                \"R\": wordnet.ADV}\n",
        "\n",
        "    return tag_dict.get(posTag, wordnet.NOUN)         # Returns the part of speech of the provided word, or if unknown, returns noun as a default"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "jAk2WSvw9u_g",
        "outputId": "32ade12e-7bb6-4bba-85e5-b395b790afe9"
      },
      "source": [
        "# Using the lemmatize function to reduce words to their root words that are also in the dictionary from the tweet text by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "# Also incorporates the custom part of speech function to help the lemmatizer\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda words: [wnl.lemmatize(word=word, pos=getPOS(word)) for word in words])\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[virginamerica, what, dhepburn, said]</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[virginamerica, plus, added, commercial, exper...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[virginamerica, i, today, must, mean, i, need,...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[virginamerica, really, aggressive, blast, obn...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[virginamerica, really, big, bad, thing]</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0              [virginamerica, what, dhepburn, said]           neutral\n",
              "1  [virginamerica, plus, added, commercial, exper...          positive\n",
              "2  [virginamerica, i, today, must, mean, i, need,...           neutral\n",
              "3  [virginamerica, really, aggressive, blast, obn...          negative\n",
              "4           [virginamerica, really, big, bad, thing]          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KEaUQ2Ge95L6"
      },
      "source": [
        "### h & i. Joining the words back together"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "boNQBDs0-X4q",
        "outputId": "e64819f1-11c1-43df-dfac-0f0313b4536d"
      },
      "source": [
        "# Combining the list of words of each tweet into a single \"sentence\" by\n",
        "# Applying a lambda function on each of the dataframe's text cell\n",
        "airData[\"text\"] = airData[\"text\"].apply(lambda words: \" \".join(words))\n",
        "airData.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>text</th>\n",
              "      <th>airline_sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>virginamerica what dhepburn said</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>virginamerica plus added commercial experience...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>virginamerica i today must mean i need take an...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>virginamerica really aggressive blast obnoxiou...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>virginamerica really big bad thing</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                text airline_sentiment\n",
              "0                   virginamerica what dhepburn said           neutral\n",
              "1  virginamerica plus added commercial experience...          positive\n",
              "2  virginamerica i today must mean i need take an...           neutral\n",
              "3  virginamerica really aggressive blast obnoxiou...          negative\n",
              "4                 virginamerica really big bad thing          negative"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "east6eF9-oV3"
      },
      "source": [
        "# 4. Vectorization"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IbkHe8XOtyUq"
      },
      "source": [
        "### a. Using CountVectorizer\n",
        "\n",
        "CountVectorizer simply counts the number of times a given word or number of words appears in each tweet and returns an array with that information.  Since we only have a little over 14,000 tweets we will limit the maximum number of features to 3000 so as not to have too many features with respect to the size of our dataset.  This will also aid in reducing the training time of our models."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6oR4Jyq-r8Ew",
        "outputId": "b8490060-8345-45f8-db73-eb6b7558573b"
      },
      "source": [
        "countV = CountVectorizer(max_features=3000)         # intializing the vectorizer limiting to 3000 words max\n",
        "countData = countV.fit_transform(airData[\"text\"])   # fitting the vectorizer and transforming the tweets into a count vectorized array\n",
        "countData.toarray()                                 # displaying a portion of the array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KZdqgvvOt7nU",
        "outputId": "d7255617-776d-460f-9165-1ca5b9f3bdcc"
      },
      "source": [
        "countData.shape # printing the shape of the vectorized data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 3000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ueK5XUkGKdqB"
      },
      "source": [
        "The tweets are now transformed into having 3000 columns, the maximum number of words we limited the vectorizer to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7-D_y0mquFju"
      },
      "source": [
        "### b. Using TfidfVectorizer\n",
        "\n",
        "Tfidf vectorization normalizes the word count by increasing the importance of words that occur in fewer of the tweets while decreasing the importance of words that occur in a large number of the tweets."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3WhiZqzeuXPL",
        "outputId": "212b3cb4-f335-4586-9482-1db53d4700fb"
      },
      "source": [
        "tfidfV = TfidfVectorizer(max_features=3000)       # intializing the vectorizer limiting to 3000 words max\n",
        "tfData = tfidfV.fit_transform(airData[\"text\"])    # fitting the vectorizer and transforming the tweets into a tfidf vectorized array\n",
        "tfData.toarray()                                  # displaying a portion of the array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AN2po7JFux60",
        "outputId": "c0fbaef1-7b7e-46e8-aef9-7d1592bb89b9"
      },
      "source": [
        "tfData.shape    # printing the shape of the vectorized data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(14640, 3000)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxY_-GKxLNa5"
      },
      "source": [
        "The tweets are now transformed into having 3000 columns, the maximum number of words we limited the vectorizer to."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NbChh5wBwEa5"
      },
      "source": [
        "# 5. Fit and Evaluate Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQTNUzFyym-q"
      },
      "source": [
        "## a. Encoding Dependent Variable\n",
        "\n",
        "The neural network needs the target variable to be an array of vectors and not simply strings (words)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxaGk4jsxzUT",
        "outputId": "7b80ae10-0514-4f19-f90b-8204610d49fa"
      },
      "source": [
        "airData[\"airline_sentiment\"].value_counts()   # printing the number and values of our target variable"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "negative    9178\n",
              "neutral     3099\n",
              "positive    2363\n",
              "Name: airline_sentiment, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H66mMJnBLmVx"
      },
      "source": [
        "There are three different sentiments: negative, neutral and positive.  We can see that there are far more negative tweets than positive tweets in the dataset.  We will use upsampling later on to balance these classes."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ieK8Ju-ysjy"
      },
      "source": [
        "# Dictionary to convert the strings of airline sentiment into integers\n",
        "sentimentDict = {\"negative\": 0,\n",
        "                 \"neutral\": 1,\n",
        "                 \"positive\": 2}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oHmfCGDKy8-E",
        "outputId": "cdc0cdef-32ed-4717-9490-cb1e6cbbb4ea"
      },
      "source": [
        "y = airData[\"airline_sentiment\"].apply(lambda x: sentimentDict[x]).values   # Converting the target classes from strings to integers\n",
        "y = to_categorical(y=y, num_classes=3)                                      # Converting the target classes into vectors the neural network can use\n",
        "y                                                                           # Displaying some of the new array"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1., 0.],\n",
              "       [0., 0., 1.],\n",
              "       [0., 1., 0.],\n",
              "       ...,\n",
              "       [0., 1., 0.],\n",
              "       [1., 0., 0.],\n",
              "       [0., 1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KljuPwuhMQja"
      },
      "source": [
        "The target class is now converted to a form the neural network can use to train."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ml1ZiVUr0NJd"
      },
      "source": [
        "## b. Custom Function to Build Neural Network for the Grid Search Method"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtX7Mi0D0vUy"
      },
      "source": [
        "# Custom function for building a ANN model based on different hyperparameters\n",
        "def buildSequential(numDenseLayers, unitsANN, dropout, optimizer=\"adam\", activation=\"relu\"):\n",
        "\n",
        "  # Intializing the new model\n",
        "  gridNN = Sequential()\n",
        "\n",
        "  # Creating a number of Dense layers equal to numDenseLayers\n",
        "  for i in np.arange(0, numDenseLayers):\n",
        "    if i == 0:\n",
        "      # Adding the first Dense layer with a number of neurons equal to number of units fed to our custom function\n",
        "      gridNN.add(Dense(unitsANN[i], activation=activation, input_shape=(3000,)))\n",
        "    else:\n",
        "      # Adding other Dense layers with a number of neurons equal to number of units fed to our custom function\n",
        "      gridNN.add(Dense(unitsANN[i], activation=activation))\n",
        "    # Adding a dropout layer with a rate equal to dropout to help control overfitting\n",
        "    gridNN.add(Dropout(dropout))\n",
        "\n",
        "  # Adding the final layer which has a number of neurons equal to the number of sentiments, in this case 3\n",
        "  # Using softmax to calculate the probablity the input text is each class\n",
        "  gridNN.add(Dense(3, activation=\"softmax\"))\n",
        "\n",
        "  # Adding the adam optimizer to our model\n",
        "  # Using categorical crossentropy for our loss since we have more than two classes\n",
        "  gridNN.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "\n",
        "  # Returning the CNN model contructed based on inputed hyperparameter values\n",
        "  return gridNN"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ud6i907w9Be"
      },
      "source": [
        "## c. CountVectorizer Model\n",
        "\n",
        "First we will train our model on using the data from CountVectorizer"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wFPbJVmvzsyM"
      },
      "source": [
        "### Splitting Data into Training, Validation and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHJZXRpRi8F-"
      },
      "source": [
        "We want to split our data into three groups: training, validation and test.  We want 35% of our data to be training, 35% to be validation and 30% to be test data.\n",
        "\n",
        "To do this we will first split our data into 30% test and 70% other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N1WPgUA9olbe",
        "outputId": "1977ee78-a6cc-4a32-de21-1b9c5f5345bf"
      },
      "source": [
        "countData = countData.toarray()   # Converting the dependent data to a regular numpy array for the neural network\n",
        "countData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       ...,\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0],\n",
              "       [0, 0, 0, ..., 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WdIbUiZyDTl"
      },
      "source": [
        "# Splitting into 30% actual test data and 70% \"train\" data that we will split below into the actual train data and validation data.\n",
        "# We are stratifying our data so that train, validation and test will all have equal proportions of each class.\n",
        "x_train, x_test, y_train, y_test = train_test_split(countData, y, test_size=0.3, stratify=y, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0I39Md3zNDKi"
      },
      "source": [
        "**SMOTE - Oversampling of the data**\n",
        "\n",
        "We will use the SMOTE function to upsample the `neutral` and `positive` tweets so they have the same number of tweets as the `negative` class.  This will help our model be able to identify each class well instead of only the dominant `negative` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ih-zUfjV3QCo",
        "outputId": "808d3a84-ad21-4ad5-b83a-8f0c56712ea3"
      },
      "source": [
        "sm = SMOTE(k_neighbors = 5, random_state=1)   #Synthetic Minority Over Sampling Technique\n",
        "x_train, y_train = sm.fit_resample(x_train, y_train)    # fitting the SMOTE algorithm to the data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0x_LhyHM7j2Q"
      },
      "source": [
        "# Splitting the rest of the data into equal parts training and validation.\n",
        "# Again we are stratifying our data to have equal proportions of each class.\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.5, stratify=y_train, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlWDVjvNzeUq",
        "outputId": "957544db-ace1-4c2f-8104-dfd52a71fbe4"
      },
      "source": [
        "# Printing the shape of our independent variables\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_val shape:\", x_val.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print()\n",
        "\n",
        "# Printing the shape of our dependent variable\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (9637, 3000)\n",
            "x_val shape: (9638, 3000)\n",
            "x_test shape: (4392, 3000)\n",
            "\n",
            "y_train shape: (9637, 3)\n",
            "y_val shape: (9638, 3)\n",
            "y_test shape: (4392, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ieqNJT7SN8xB"
      },
      "source": [
        "We see our training and validation data has been upsampled and is of equal size.  The test data remained untouched and is 30% of the original dataset size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9M9iM28XoHl"
      },
      "source": [
        "### Grid Search Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jjL96pFbqD7g"
      },
      "source": [
        "Grid search is a time intensive process.  The more hyperparameters which are tuned and the greater the number of options we give for each hyperparameter the more combinations we have to train.  Below we have chosen to tune some of the hyperparameters yielding 48 different combinations to train with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1BO8-LPf46EX"
      },
      "source": [
        "# The options for the number of dense layers\n",
        "numDenseLayers = [1, 2, 3, 4]\n",
        "\n",
        "# The options for the number of neurons in each dense layer\n",
        "unitsANN = [[64, 64, 64, 64],\n",
        "            [8, 16, 32, 64],\n",
        "            [16, 32, 64, 128],\n",
        "            [32, 32, 32, 32],]\n",
        "\n",
        "# The options for the dropout values for each dense layer\n",
        "dropout = [0.5, 0.3, 0.1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Zqd7d2t4wDq"
      },
      "source": [
        "### Fitting the CountVectorizer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "danaP4KEr8PN"
      },
      "source": [
        "We now will loop through the different combinations of hyperparameters and fit the model.  We will also employ two Keras callbacks:\n",
        "- EarlyStopping: stops the training process when the current model has not improved for a given number of epochs\n",
        "- ModelCheckpoint: saves the best version of the current model at each epoch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfGQwKwQ3mnF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50bac931-9471-421c-bcbf-6c4fdecac569"
      },
      "source": [
        "i = 0                 # Initializing a counter to number the current model\n",
        "bestValLoss = 1000    # Initializing the current \"best\" validation loss really high so any model will be performing better than it\n",
        "\n",
        "# Looping through the different hyperparameter options given above, fitting the model with each combination\n",
        "\n",
        "for dp in dropout:\n",
        "  for nd in numDenseLayers:\n",
        "    for ua in unitsANN:\n",
        "      # Building the current model with a combination of hyperparameters using our custom function\n",
        "      model = buildSequential(nd, ua, dp)\n",
        "\n",
        "      # Setting the early stopping callback to stop training when the validation loss has not improved after 10 epochs\n",
        "      early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=10)\n",
        "\n",
        "      # Setting the model checkpoint to save the weights of the current model when the validation loss has improved\n",
        "      model_checkpoint = ModelCheckpoint(filepath= \"model_\" + str(i) + \".h5\",\n",
        "                          monitor = \"val_loss\",\n",
        "                          verbose = 0,\n",
        "                          save_best_only = True,\n",
        "                          save_weights_only = True,\n",
        "                          mode = \"auto\",\n",
        "                          save_freq = \"epoch\")\n",
        "\n",
        "      # Training the model with 50 as our batch size and 100 epochs\n",
        "      # The training will probably stop each time before 100 epochs based on the early stopping callback\n",
        "      # Using x_val and y_val as the validation data\n",
        "      model.fit(x = x_train,\n",
        "                y = y_train,\n",
        "                batch_size=50,\n",
        "                epochs=100,\n",
        "                verbose=0,\n",
        "                validation_data=(x_val, y_val),\n",
        "                callbacks=[early_stopping, model_checkpoint])\n",
        "      \n",
        "      # Loading the weights of the current model saved from its best version\n",
        "      # The best version of the current model has the lowest validation loss\n",
        "      model.load_weights(filepath=\"model_\" + str(i) + \".h5\")\n",
        "      \n",
        "      # Calculating the validation loss and accuracy for the best version of the current model\n",
        "      valLoss, valAcc = model.evaluate(x=x_val, y=y_val)\n",
        "\n",
        "      # If the validation loss of the current model is better than all other previous models...\n",
        "      if valLoss < bestValLoss:\n",
        "        bestModelNumber = i                                     # Store the current model number\n",
        "        bestValLoss = valLoss                                   # Store the current model validation score as the best\n",
        "        bestParameters = [nd, ua, dp]   # Store the current model hyperparameters as the best\n",
        "        bestModel = model                                       # Store the current model as the best\n",
        "\n",
        "      # Displaying the finished model number and it's validation loss and accuracy\n",
        "      print(\"Model\", i, \" finished with validation loss of\", valLoss, \"and validation accuracy of\", valAcc)\n",
        "\n",
        "      # Increasing the model number by one for the next model\n",
        "      i += 1\n",
        "\n",
        "      # Clearing up memory (RAM)\n",
        "      backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5557 - accuracy: 0.7682\n",
            "Model 0  finished with validation loss of 0.5556889176368713 and validation accuracy of 0.7682091593742371\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5772 - accuracy: 0.7726\n",
            "Model 1  finished with validation loss of 0.5771964192390442 and validation accuracy of 0.7725669145584106\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5624 - accuracy: 0.7700\n",
            "Model 2  finished with validation loss of 0.5623536109924316 and validation accuracy of 0.7699730396270752\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5520 - accuracy: 0.7694\n",
            "Model 3  finished with validation loss of 0.5520438551902771 and validation accuracy of 0.7693504691123962\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5669 - accuracy: 0.7685\n",
            "Model 4  finished with validation loss of 0.5668622851371765 and validation accuracy of 0.7685204148292542\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.6360 - accuracy: 0.7545\n",
            "Model 5  finished with validation loss of 0.6360357403755188 and validation accuracy of 0.7545133829116821\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5863 - accuracy: 0.7712\n",
            "Model 6  finished with validation loss of 0.5863429307937622 and validation accuracy of 0.7712181210517883\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5785 - accuracy: 0.7712\n",
            "Model 7  finished with validation loss of 0.5785275101661682 and validation accuracy of 0.7712181210517883\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5674 - accuracy: 0.7673\n",
            "Model 8  finished with validation loss of 0.5674463510513306 and validation accuracy of 0.7672753930091858\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.7152 - accuracy: 0.6841\n",
            "Model 9  finished with validation loss of 0.7151748538017273 and validation accuracy of 0.6840630769729614\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.6677 - accuracy: 0.7203\n",
            "Model 10  finished with validation loss of 0.6677095293998718 and validation accuracy of 0.7202739119529724\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.7550\n",
            "Model 11  finished with validation loss of 0.6182320713996887 and validation accuracy of 0.7550321817398071\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.6002 - accuracy: 0.7590\n",
            "Model 12  finished with validation loss of 0.6001781821250916 and validation accuracy of 0.7589749097824097\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.7013 - accuracy: 0.6681\n",
            "Model 13  finished with validation loss of 0.7012540698051453 and validation accuracy of 0.6680846810340881\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.6500 - accuracy: 0.7119\n",
            "Model 14  finished with validation loss of 0.650041401386261 and validation accuracy of 0.7118696570396423\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.7012 - accuracy: 0.6709\n",
            "Model 15  finished with validation loss of 0.7011510729789734 and validation accuracy of 0.6708860993385315\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5533 - accuracy: 0.7708\n",
            "Model 16  finished with validation loss of 0.5533363223075867 and validation accuracy of 0.7708030939102173\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7689\n",
            "Model 17  finished with validation loss of 0.5654970407485962 and validation accuracy of 0.7689354419708252\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5609 - accuracy: 0.7707\n",
            "Model 18  finished with validation loss of 0.5608576536178589 and validation accuracy of 0.7706993222236633\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5624 - accuracy: 0.7691\n",
            "Model 19  finished with validation loss of 0.5623578429222107 and validation accuracy of 0.7691429853439331\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5580 - accuracy: 0.7718\n",
            "Model 20  finished with validation loss of 0.557969868183136 and validation accuracy of 0.7718406319618225\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.7659\n",
            "Model 21  finished with validation loss of 0.5831605792045593 and validation accuracy of 0.7659265398979187\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7695\n",
            "Model 22  finished with validation loss of 0.5675874948501587 and validation accuracy of 0.7694542407989502\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5632 - accuracy: 0.7696\n",
            "Model 23  finished with validation loss of 0.5631829500198364 and validation accuracy of 0.7695580124855042\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5536 - accuracy: 0.7707\n",
            "Model 24  finished with validation loss of 0.5536041259765625 and validation accuracy of 0.7706993222236633\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5974 - accuracy: 0.7639\n",
            "Model 25  finished with validation loss of 0.5974467396736145 and validation accuracy of 0.7638514041900635\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5723 - accuracy: 0.7696\n",
            "Model 26  finished with validation loss of 0.5723458528518677 and validation accuracy of 0.7695580124855042\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5737 - accuracy: 0.7615\n",
            "Model 27  finished with validation loss of 0.5736655592918396 and validation accuracy of 0.7614650130271912\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7662\n",
            "Model 28  finished with validation loss of 0.5688422918319702 and validation accuracy of 0.7662377953529358\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.6711 - accuracy: 0.7084\n",
            "Model 29  finished with validation loss of 0.6711445450782776 and validation accuracy of 0.7084457278251648\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5819 - accuracy: 0.7594\n",
            "Model 30  finished with validation loss of 0.5819495916366577 and validation accuracy of 0.7593899369239807\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5756 - accuracy: 0.7710\n",
            "Model 31  finished with validation loss of 0.5756200551986694 and validation accuracy of 0.7710105776786804\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5558 - accuracy: 0.7713\n",
            "Model 32  finished with validation loss of 0.5558421611785889 and validation accuracy of 0.7713218331336975\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7685\n",
            "Model 33  finished with validation loss of 0.5602991580963135 and validation accuracy of 0.7685204148292542\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5602 - accuracy: 0.7668\n",
            "Model 34  finished with validation loss of 0.5601832270622253 and validation accuracy of 0.7667565941810608\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5552 - accuracy: 0.7685\n",
            "Model 35  finished with validation loss of 0.5551583170890808 and validation accuracy of 0.7685204148292542\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5634 - accuracy: 0.7543\n",
            "Model 36  finished with validation loss of 0.5634246468544006 and validation accuracy of 0.754305899143219\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5660 - accuracy: 0.7686\n",
            "Model 37  finished with validation loss of 0.5660375952720642 and validation accuracy of 0.7686241865158081\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5706 - accuracy: 0.7671\n",
            "Model 38  finished with validation loss of 0.5705513954162598 and validation accuracy of 0.7670678496360779\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5609 - accuracy: 0.7722\n",
            "Model 39  finished with validation loss of 0.5609432458877563 and validation accuracy of 0.7721518874168396\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7739\n",
            "Model 40  finished with validation loss of 0.5507962703704834 and validation accuracy of 0.7739157676696777\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5724 - accuracy: 0.7671\n",
            "Model 41  finished with validation loss of 0.5723516941070557 and validation accuracy of 0.7670678496360779\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7639\n",
            "Model 42  finished with validation loss of 0.5675548315048218 and validation accuracy of 0.7638514041900635\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7565\n",
            "Model 43  finished with validation loss of 0.5651441812515259 and validation accuracy of 0.7564847469329834\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5577 - accuracy: 0.7676\n",
            "Model 44  finished with validation loss of 0.5576799511909485 and validation accuracy of 0.7675866484642029\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.6104 - accuracy: 0.7434\n",
            "Model 45  finished with validation loss of 0.6103551983833313 and validation accuracy of 0.7434114813804626\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5792 - accuracy: 0.7640\n",
            "Model 46  finished with validation loss of 0.5792456865310669 and validation accuracy of 0.7639551758766174\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5584 - accuracy: 0.7592\n",
            "Model 47  finished with validation loss of 0.558392345905304 and validation accuracy of 0.7591823935508728\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JSoo6cBSrkU8",
        "outputId": "4b963949-e62e-4c6e-bf00-bc1e30aae849"
      },
      "source": [
        "# Printing which model performed best\n",
        "print(\"Best Model Number:\", bestModelNumber)\n",
        "print(\"Best Model Validation Loss\", bestValLoss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Model Number: 40\n",
            "Best Model Validation Loss 0.5507962703704834\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "worR_cyTrmug",
        "outputId": "4722854e-2104-42ac-b4d5-9cde2a89457a"
      },
      "source": [
        "# Printing the best parameters\n",
        "bestParameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, [64, 64, 64, 64], 0.1]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7flRULJrpO3"
      },
      "source": [
        "The best model has the following hyperparameters:\n",
        "- Number of dense layers: 3 with 1 additional softmax layer\n",
        "- Number of neurons: 64, 64, 64\n",
        "- Dropout rate: 0.1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Tp1NU95r7FG"
      },
      "source": [
        "# Rebuilding the best model with the using the best parameters\n",
        "bestModel = buildSequential(bestParameters[0],\n",
        "                            bestParameters[1],\n",
        "                            bestParameters[2],)\n",
        "\n",
        "# Loading the weights for the best model that were saved by the checkpoint\n",
        "bestModel.load_weights(\"model_\" + str(bestModelNumber) + \".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6LwshuKysAxW",
        "outputId": "c9552f38-c58f-4df1-f990-868a31978646"
      },
      "source": [
        "# Printing the best model's validation accuracy\n",
        "print(\"Best Model Validation Accuracy:\", bestModel.evaluate(x=x_val, y=y_val)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "302/302 [==============================] - 1s 2ms/step - loss: 0.5508 - accuracy: 0.7739\n",
            "Best Model Validation Accuracy: 0.7739157676696777\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NyTe-W8sOf07"
      },
      "source": [
        "The model's validation accuracy is okay at 77%.  We will now see if the TfidfVectorizer method works better."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HleYGwZfyQtu"
      },
      "source": [
        "## d. TfidfVectorizer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UppBDosoyhc2"
      },
      "source": [
        "### Splitting Data into Training, Validation and Testing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odTvtu_1ylFd"
      },
      "source": [
        "We want to split our data into three groups: training, validation and test.  We want 35% of our data to be training, 35% to be validation and 30% to be test data.\n",
        "\n",
        "To do this we will first split our data into 30% test and 70% other."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "It2pDcA9yV8S",
        "outputId": "cd46d902-ef42-4409-8599-2e5a1c6b62fb"
      },
      "source": [
        "tfData = tfData.toarray()   # Converting the dependent data to a regular numpy array for the neural network\n",
        "tfData"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       ...,\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.],\n",
              "       [0., 0., 0., ..., 0., 0., 0.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNyAoDn6yrnh"
      },
      "source": [
        "# Splitting into 30% actual test data and 70% \"train\" data that we will split below into the actual train data and validation data.\n",
        "# We are stratifying our data so that train, validation and test will all have equal proportions of each class.\n",
        "x_train, x_test, y_train, y_test = train_test_split(tfData, y, test_size=0.3, stratify=y, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFBSSuFjPDEm"
      },
      "source": [
        "**SMOTE - Oversampling of the data**\n",
        "\n",
        "We will use the SMOTE function to upsample the `neutral` and `positive` tweets so they have the same number of tweets as the `negative` class.  This will help our model be able to identify each class well instead of only the dominant `negative` class."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8U1k3xkI3ZJx",
        "outputId": "56e86236-aab3-426f-9c65-232e55d3df4c"
      },
      "source": [
        "sm = SMOTE(k_neighbors = 5, random_state=1)   #Synthetic Minority Over Sampling Technique\n",
        "x_train, y_train = sm.fit_resample(x_train, y_train)    # fitting the SMOTE algorithm to the data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function safe_indexing is deprecated; safe_indexing is deprecated in version 0.22 and will be removed in version 0.24.\n",
            "  warnings.warn(msg, category=FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fUi7J0YRyu5Y"
      },
      "source": [
        "# Splitting the rest of the data into equal parts training and validation.\n",
        "# Again we are stratifying our data to have equal proportions of each class.\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.5, stratify=y_train, random_state=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XGV5K82lyy4x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "534933cb-d1ef-4865-ad74-6d03cc4a4def"
      },
      "source": [
        "# Printing the shape of our independent data\n",
        "print(\"x_train shape:\", x_train.shape)\n",
        "print(\"x_val shape:\", x_val.shape)\n",
        "print(\"x_test shape:\", x_test.shape)\n",
        "print()\n",
        "\n",
        "# Printing the shape of our dependent data\n",
        "print(\"y_train shape:\", y_train.shape)\n",
        "print(\"y_val shape:\", y_val.shape)\n",
        "print(\"y_test shape:\", y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x_train shape: (9637, 3000)\n",
            "x_val shape: (9638, 3000)\n",
            "x_test shape: (4392, 3000)\n",
            "\n",
            "y_train shape: (9637, 3)\n",
            "y_val shape: (9638, 3)\n",
            "y_test shape: (4392, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2y7Wn2hHy_5k"
      },
      "source": [
        "### Grid Search Parameters"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mw314EuDy_5l"
      },
      "source": [
        "Grid search is a time intensive process.  The more hyperparameters which are tuned and the greater the number of options we give for each hyperparameter the more combinations we have to train.  Below we have chosen to tune some of the hyperparameters yielding 48 different combinations to train with."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9KrucPSXy_5l"
      },
      "source": [
        "# The options for the number of dense layers\n",
        "numDenseLayers = [1, 2, 3, 4]\n",
        "\n",
        "# The options for the number of neurons in each dense layer\n",
        "unitsANN = [[64, 64, 64, 64],\n",
        "            [8, 16, 32, 64],\n",
        "            [16, 32, 64, 128],\n",
        "            [32, 32, 32, 32],]\n",
        "\n",
        "# The options for the dropout values for each dense layer\n",
        "dropout = [0.5, 0.3, 0.1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XuELLW5lzJZs"
      },
      "source": [
        "### Fitting the TfidfVectorizer Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ng1ajeS0zJZs"
      },
      "source": [
        "We now will loop through the different combinations of hyperparameters and fit the model.  We will also employ two Keras callbacks:\n",
        "- EarlyStopping: stops the training process when the current model has not improved for a given number of epochs\n",
        "- ModelCheckpoint: saves the best version of the current model at each epoch\n",
        "\n",
        "We will also simply add on any new best models instead of starting over so as to retain the best model between CountVectorizer and TfidfVectorizer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SaFK2yXzJZt",
        "outputId": "c14c4264-d2c4-4299-da2a-ee7f055c9bee"
      },
      "source": [
        "# Looping through the different hyperparameter options given above, fitting the model with each combination\n",
        "\n",
        "for dp in dropout:\n",
        "  for nd in numDenseLayers:\n",
        "    for ua in unitsANN:\n",
        "      # Building the current model with a combination of hyperparameters using our custom function\n",
        "      model = buildSequential(nd, ua, dp)\n",
        "\n",
        "      # Setting the early stopping callback to stop training when the validation loss has not improved after 10 epochs\n",
        "      early_stopping = EarlyStopping(monitor=\"val_loss\", min_delta=0.001, patience=10)\n",
        "\n",
        "      # Setting the model checkpoint to save the weights of the current model when the validation loss has improved\n",
        "      model_checkpoint = ModelCheckpoint(filepath= \"model_\" + str(i) + \".h5\",\n",
        "                          monitor = \"val_loss\",\n",
        "                          verbose = 0,\n",
        "                          save_best_only = True,\n",
        "                          save_weights_only = True,\n",
        "                          mode = \"auto\",\n",
        "                          save_freq = \"epoch\")\n",
        "\n",
        "      # Training the model with 32 batches and 100 epochs\n",
        "      # The training will probably stop each time before 100 epochs based on the early stopping callback\n",
        "      # Using x_val and y_val as the validation data\n",
        "      model.fit(x = x_train,\n",
        "                y = y_train,\n",
        "                batch_size=50,\n",
        "                epochs=100,\n",
        "                verbose=0,\n",
        "                validation_data=(x_val, y_val),\n",
        "                callbacks=[early_stopping, model_checkpoint])\n",
        "      \n",
        "      # Loading the weights of the current model saved from its best version\n",
        "      # The best version of the current model has the lowest validation loss\n",
        "      model.load_weights(filepath=\"model_\" + str(i) + \".h5\")\n",
        "      \n",
        "      # Calculating the validation loss and accuracy for the best version of the current model\n",
        "      valLoss, valAcc = model.evaluate(x=x_val, y=y_val)\n",
        "\n",
        "      # If the validation loss of the current model is better than all other previous models...\n",
        "      if valLoss < bestValLoss:\n",
        "        bestModelNumber = i                                     # Store the current model number\n",
        "        bestValLoss = valLoss                                   # Store the current model validation score as the best\n",
        "        bestParameters = [nd, ua, dp]   # Store the current model hyperparameters as the best\n",
        "        bestModel = model                                       # Store the current model as the best\n",
        "\n",
        "      # Displaying the finished model number and it's validation loss and accuracy\n",
        "      print(\"Model\", i, \" finished with validation loss of\", valLoss, \"and validation accuracy of\", valAcc)\n",
        "\n",
        "      # Increasing the model number by one for the next model\n",
        "      i += 1\n",
        "\n",
        "      # Clearing up memory (RAM)\n",
        "      backend.clear_session()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3913 - accuracy: 0.8571\n",
            "Model 48  finished with validation loss of 0.39129844307899475 and validation accuracy of 0.8571280241012573\n",
            "302/302 [==============================] - 0s 1ms/step - loss: 0.4023 - accuracy: 0.8555\n",
            "Model 49  finished with validation loss of 0.4023299813270569 and validation accuracy of 0.8554679155349731\n",
            "302/302 [==============================] - 0s 1ms/step - loss: 0.3945 - accuracy: 0.8562\n",
            "Model 50  finished with validation loss of 0.39450666308403015 and validation accuracy of 0.856194257736206\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3974 - accuracy: 0.8529\n",
            "Model 51  finished with validation loss of 0.39740225672721863 and validation accuracy of 0.8528740406036377\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3944 - accuracy: 0.8593\n",
            "Model 52  finished with validation loss of 0.39435669779777527 and validation accuracy of 0.8593069314956665\n",
            "302/302 [==============================] - 0s 1ms/step - loss: 0.4797 - accuracy: 0.8375\n",
            "Model 53  finished with validation loss of 0.4797327220439911 and validation accuracy of 0.8375181555747986\n",
            "302/302 [==============================] - 0s 2ms/step - loss: 0.3978 - accuracy: 0.8580\n",
            "Model 54  finished with validation loss of 0.3978063464164734 and validation accuracy of 0.8579580783843994\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3963 - accuracy: 0.8571\n",
            "Model 55  finished with validation loss of 0.3962900936603546 and validation accuracy of 0.8571280241012573\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8620\n",
            "Model 56  finished with validation loss of 0.39733076095581055 and validation accuracy of 0.8620045781135559\n",
            "302/302 [==============================] - 0s 1ms/step - loss: 0.4750 - accuracy: 0.8426\n",
            "Model 57  finished with validation loss of 0.475017249584198 and validation accuracy of 0.8426021933555603\n",
            "302/302 [==============================] - 0s 2ms/step - loss: 0.4282 - accuracy: 0.8556\n",
            "Model 58  finished with validation loss of 0.42822909355163574 and validation accuracy of 0.8555716872215271\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4195 - accuracy: 0.8659\n",
            "Model 59  finished with validation loss of 0.4195047914981842 and validation accuracy of 0.8659473061561584\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4133 - accuracy: 0.8741\n",
            "Model 60  finished with validation loss of 0.4133024513721466 and validation accuracy of 0.8741440176963806\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4821 - accuracy: 0.8432\n",
            "Model 61  finished with validation loss of 0.482110857963562 and validation accuracy of 0.8432247638702393\n",
            "302/302 [==============================] - 0s 2ms/step - loss: 0.4294 - accuracy: 0.8566\n",
            "Model 62  finished with validation loss of 0.42943647503852844 and validation accuracy of 0.8566092252731323\n",
            "302/302 [==============================] - 0s 2ms/step - loss: 0.4840 - accuracy: 0.8534\n",
            "Model 63  finished with validation loss of 0.4840281307697296 and validation accuracy of 0.8533928394317627\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8551\n",
            "Model 64  finished with validation loss of 0.39734601974487305 and validation accuracy of 0.8550528883934021\n",
            "302/302 [==============================] - 0s 1ms/step - loss: 0.3949 - accuracy: 0.8573\n",
            "Model 65  finished with validation loss of 0.3949348032474518 and validation accuracy of 0.8573355674743652\n",
            "302/302 [==============================] - 0s 1ms/step - loss: 0.4033 - accuracy: 0.8524\n",
            "Model 66  finished with validation loss of 0.40328913927078247 and validation accuracy of 0.8523552417755127\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3963 - accuracy: 0.8555\n",
            "Model 67  finished with validation loss of 0.3963327407836914 and validation accuracy of 0.8554679155349731\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3941 - accuracy: 0.8589\n",
            "Model 68  finished with validation loss of 0.39413297176361084 and validation accuracy of 0.8588919043540955\n",
            "302/302 [==============================] - 0s 2ms/step - loss: 0.4100 - accuracy: 0.8520\n",
            "Model 69  finished with validation loss of 0.41004323959350586 and validation accuracy of 0.8520439863204956\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4034 - accuracy: 0.8553\n",
            "Model 70  finished with validation loss of 0.40336912870407104 and validation accuracy of 0.85526043176651\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3973 - accuracy: 0.8549\n",
            "Model 71  finished with validation loss of 0.3973163664340973 and validation accuracy of 0.8549491763114929\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8653\n",
            "Model 72  finished with validation loss of 0.38890406489372253 and validation accuracy of 0.8653247356414795\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4398 - accuracy: 0.8470\n",
            "Model 73  finished with validation loss of 0.4397675395011902 and validation accuracy of 0.8469599485397339\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4205 - accuracy: 0.8619\n",
            "Model 74  finished with validation loss of 0.4204701781272888 and validation accuracy of 0.861900806427002\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4072 - accuracy: 0.8636\n",
            "Model 75  finished with validation loss of 0.4071657657623291 and validation accuracy of 0.8635609149932861\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3997 - accuracy: 0.8685\n",
            "Model 76  finished with validation loss of 0.39966756105422974 and validation accuracy of 0.8685411810874939\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4566 - accuracy: 0.8382\n",
            "Model 77  finished with validation loss of 0.4566463232040405 and validation accuracy of 0.8382444381713867\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4160 - accuracy: 0.8603\n",
            "Model 78  finished with validation loss of 0.41599389910697937 and validation accuracy of 0.8603444695472717\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4179 - accuracy: 0.8615\n",
            "Model 79  finished with validation loss of 0.4178718030452728 and validation accuracy of 0.8614857792854309\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4022 - accuracy: 0.8517\n",
            "Model 80  finished with validation loss of 0.40218496322631836 and validation accuracy of 0.8517327308654785\n",
            "302/302 [==============================] - 0s 1ms/step - loss: 0.3957 - accuracy: 0.8532\n",
            "Model 81  finished with validation loss of 0.39570385217666626 and validation accuracy of 0.8531852960586548\n",
            "302/302 [==============================] - 0s 1ms/step - loss: 0.3977 - accuracy: 0.8520\n",
            "Model 82  finished with validation loss of 0.3976837396621704 and validation accuracy of 0.8520439863204956\n",
            "302/302 [==============================] - 0s 2ms/step - loss: 0.4010 - accuracy: 0.8526\n",
            "Model 83  finished with validation loss of 0.4010365903377533 and validation accuracy of 0.8525627851486206\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4070 - accuracy: 0.8565\n",
            "Model 84  finished with validation loss of 0.4070340692996979 and validation accuracy of 0.8565055131912231\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4050 - accuracy: 0.8541\n",
            "Model 85  finished with validation loss of 0.4049520492553711 and validation accuracy of 0.8541191220283508\n",
            "302/302 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8521\n",
            "Model 86  finished with validation loss of 0.4034573435783386 and validation accuracy of 0.8521477580070496\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4105 - accuracy: 0.8484\n",
            "Model 87  finished with validation loss of 0.41049134731292725 and validation accuracy of 0.8484125137329102\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3898 - accuracy: 0.8586\n",
            "Model 88  finished with validation loss of 0.38980528712272644 and validation accuracy of 0.8585805892944336\n",
            "302/302 [==============================] - 0s 2ms/step - loss: 0.4142 - accuracy: 0.8490\n",
            "Model 89  finished with validation loss of 0.4141908586025238 and validation accuracy of 0.8490350842475891\n",
            "302/302 [==============================] - 0s 2ms/step - loss: 0.4090 - accuracy: 0.8555\n",
            "Model 90  finished with validation loss of 0.40900158882141113 and validation accuracy of 0.8554679155349731\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4023 - accuracy: 0.8570\n",
            "Model 91  finished with validation loss of 0.40234676003456116 and validation accuracy of 0.8570242524147034\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3919 - accuracy: 0.8595\n",
            "Model 92  finished with validation loss of 0.39187854528427124 and validation accuracy of 0.8595144152641296\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4260 - accuracy: 0.8470\n",
            "Model 93  finished with validation loss of 0.4260319769382477 and validation accuracy of 0.8469599485397339\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4346 - accuracy: 0.8499\n",
            "Model 94  finished with validation loss of 0.4346442222595215 and validation accuracy of 0.8498651385307312\n",
            "302/302 [==============================] - 1s 2ms/step - loss: 0.4219 - accuracy: 0.8538\n",
            "Model 95  finished with validation loss of 0.4218806028366089 and validation accuracy of 0.8538078665733337\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_qAO_tRzJZu",
        "outputId": "36c1ec18-e152-47d0-b165-82c636d0359f"
      },
      "source": [
        "# Printing which model performed best\n",
        "print(\"Best Model Number:\", bestModelNumber)\n",
        "print(\"Best Model Validation Loss\", bestValLoss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Best Model Number: 72\n",
            "Best Model Validation Loss 0.38890406489372253\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AKNJ8WEFEI6k",
        "outputId": "eca2faab-f57f-4435-b10c-2c5c495080dd"
      },
      "source": [
        "# Printing the best parameters\n",
        "bestParameters"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, [64, 64, 64, 64], 0.3]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1hlGDnMlEOqX"
      },
      "source": [
        "The best model has the following hyperparameters:\n",
        "- Number of dense layers: 3 with 1 additional softmax layer\n",
        "- Number of neurons: 64, 64\n",
        "- Dropout rate: 0.3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xn8KOq8fEKvA"
      },
      "source": [
        "# Rebuilding the best model with the using the best parameters\n",
        "bestModel = buildSequential(bestParameters[0],\n",
        "                            bestParameters[1],\n",
        "                            bestParameters[2],)\n",
        "\n",
        "# Loading the weights for the best model that were saved by the checkpoint\n",
        "bestModel.load_weights(\"model_\" + str(bestModelNumber) + \".h5\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1HTx1JXTETlH",
        "outputId": "9e3a35d2-56c4-40be-b5cf-6876e1011c65"
      },
      "source": [
        "# Printing the best model's validation accuracy\n",
        "print(\"Best Model Validation Accuracy:\", bestModel.evaluate(x=x_val, y=y_val)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "302/302 [==============================] - 1s 2ms/step - loss: 0.3889 - accuracy: 0.8653\n",
            "Best Model Validation Accuracy: 0.8653247356414795\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wBhKXq93PmB9"
      },
      "source": [
        "The validation accuracy of our TfidfVectorizer model is significantly better than the CountVectorizer model at 86.5%.  This will be our best model that we keep."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yftDgalrsC9u"
      },
      "source": [
        "# 6. Summary and Model Evaluation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i19gUX8wsV-9"
      },
      "source": [
        "## Model Evaluation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LUYaF7CuscAV",
        "outputId": "678aa40f-cf46-4bdd-c766-347bd06ec5ea"
      },
      "source": [
        "# Using the best model to predict the test set\n",
        "y_pred = np.argmax(bestModel.predict(x=x_test), axis=1)\n",
        "y_pred"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, ..., 2, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vIA4j4WGtkDo",
        "outputId": "907102c3-885c-4830-cb71-3f11cd3e2263"
      },
      "source": [
        "# Creating a dictionary to reverse the encoding done to our target variable\n",
        "ivd = {v: k for k, v in sentimentDict.items()}\n",
        "ivd"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'negative', 1: 'neutral', 2: 'positive'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 338
        },
        "id": "65dkL6v_sef1",
        "outputId": "8ea293c6-0e0d-488c-966a-93e06d5a4560"
      },
      "source": [
        "# Creating a confusion matrix for the test data of our best model\n",
        "cm = confusion_matrix(y_true=np.argmax(y_test, axis=1), y_pred=y_pred)\n",
        "\n",
        "#plt.figure(figsize=(15,10))                   # Increasing the size of the confusion matrix\n",
        "sns.heatmap(data=cm, annot=True, fmt=\".0f\")   # Plotting the confusion matrix as a heatmap\n",
        "\n",
        "plt.xlabel(\"Predicted Label\", fontsize=14)    # Labeling the predicted axis\n",
        "plt.ylabel(\"Actual Label\", fontsize=14)       # Labeling the true axis\n",
        "\n",
        "plt.xticks(ticks=np.arange(0,3), labels=list(ivd.values()), rotation=45)        # Placing the sentiment class names\n",
        "plt.yticks(ticks=np.arange(0,3), labels=list(ivd.values()), rotation=45)        # Placing the sentiment class names\n",
        "\n",
        "plt.title(\"Confusion Matrix for Best Model\", fontsize=20)   # Adding a title\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_uj_0LPEtsTC",
        "outputId": "7fad3844-72d4-480f-ee01-9edb854c3406"
      },
      "source": [
        "# Displaying the classification report with the test data\n",
        "print(classification_report(y_true=[ivd[x] for x in np.argmax(y_test, axis=1)], y_pred=[ivd[x] for x in y_pred]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "    negative       0.87      0.83      0.85      2753\n",
            "     neutral       0.56      0.60      0.58       930\n",
            "    positive       0.65      0.71      0.68       709\n",
            "\n",
            "    accuracy                           0.76      4392\n",
            "   macro avg       0.70      0.71      0.70      4392\n",
            "weighted avg       0.77      0.76      0.77      4392\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "isCJbpamQDG4"
      },
      "source": [
        "From the above confusion matrix and classification report the model performs best when identifying negative tweets and least well when identifying neutral tweets.  On average, if the model mis-identifies a neutral tweet it classifies the tweet as negative three times as often as positive.  Thus, our model could be said to be more conservative in nature by erring on the safe side and moving tweets it is less sure of towards the negative end of the spectrum.  This way, if a problem is arising for an airline on Twitter the company will have less negative reviews slip through their screening."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGz3zAirs518",
        "outputId": "47a530d7-2a3a-4ebb-dfa6-0cb13f8d0eb1"
      },
      "source": [
        "# Printing the best model's test accuracy\n",
        "print(\"Best Model Test Accuracy:\", bestModel.evaluate(x=x_test, y=y_test)[1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "138/138 [==============================] - 0s 2ms/step - loss: 0.6949 - accuracy: 0.7623\n",
            "Best Model Test Accuracy: 0.7622950673103333\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6RM8UVh4RpTC"
      },
      "source": [
        "The test accuracy shows that our model is overfit somewhat since the validation accuracy is greater than the test accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-6uMSDz5Sri6"
      },
      "source": [
        "## Summary\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWVNPWKsTgsR"
      },
      "source": [
        "To build this model we employed several preprocessing steps in order to clean the data.  Without cleaning the text data our model would not be able to generalize and train on the tweets. These were:\n",
        "- HTML tag removal: eliminated HTML tags from the text\n",
        "- Contraction removal: converted words such as can't into can not to reduce the dimensionality of our data\n",
        "- Tokenization: split each tweet into individual words which will be used later as features for our model to learn from\n",
        "- Number removal: removed numbers such as 10,000 from the text as the scale of the numbers should not affect this model\n",
        "- Special character removal: converted any characters such as é to their nearest english equivalent\n",
        "- Punctuation removal: eliminated punctuation from our model to employ a bag of words approach\n",
        "  - This does remove some contextual meaning from the data however it does reduce the dimensionality of the data and is not usually helpful to the model\n",
        "- Stop word removal: removed words that do not carry actual information from the text, such as \"the\" and \"as\"\n",
        "- Conversion to lowercase: converted all characters to lowercase so that \"The\" and \"the\" will be the same word instead of two different words\n",
        "- Lemmatize: reduced all words to a root word that is present in the dictionary striving to reduce the dimensionality of the text and get to the actual meaning of each word in the text\n",
        "  - i.e. roots becomes root\n",
        "- Joining the words back together: simply turned the list of separate words back into a continuous string for the vectorizing functions to operate on"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2fUqDfqiWn7q"
      },
      "source": [
        "We also used two different types of word vectorization: CountVectorizer and TfidfVectorizer.  Vectorizing the text data converts words into individual vectors or features for our model to train with.  In each case we set the maximum number of features (or words) to the 3000 highest weight words as to reduce training time and to have less features than the number of tweets our dataset has.  The two vectorization methods work by:\n",
        "- CountVectorizer\n",
        "  - Counting the frequency of each word present in a given tweet\n",
        "  - Assigning that frequency as the weight of the word for that particular tweet\n",
        "  - Normalizing the weights by dividing each weight by the maximum weight so they range from 0 to 1\n",
        "  - The weights of words do not take into account other tweets (documents)\n",
        "- TfidfVectorizer\n",
        "  - Counting the frequency of each word present in a tweet\n",
        "  - Dividing that count by the total number of words in that tweet\n",
        "    - This is known as the term frequency\n",
        "  - Counting how many documents (tweets) each word is present in\n",
        "  - Dividing the total number of documents (tweets) by the previous count\n",
        "  - Applying a logrithmic scale to the previous division\n",
        "    - This is known as the inverse document frequency\n",
        "  - Multiplying the term frequency by the inverse document frequency\n",
        "    - This lowers the importance (weights) of words which appear in most of the documents while increasing the importance (weights) of words which appear in only a few of the documents"
      ]
    }
  ]
}